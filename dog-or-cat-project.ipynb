{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os, cv2, random, time, shutil\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tqdm import tqdm\nnp.random.seed(42)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom keras.utils import plot_model\n%matplotlib inline \n\nimport keras\nfrom keras.models import Sequential\nfrom keras import backend\nfrom keras.applications import ResNet50\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.inception_v3 import InceptionV3,preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD\nfrom keras.models import Model, load_model\nfrom keras.layers import  AveragePooling2D, GlobalAveragePooling2D,Dropout\nfrom keras.layers import Dense, Flatten, Dropout, Lambda, Input, Concatenate, concatenate\nfrom keras.utils import to_categorical","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-30T16:48:34.694838Z","iopub.execute_input":"2022-07-30T16:48:34.695249Z","iopub.status.idle":"2022-07-30T16:48:34.713781Z","shell.execute_reply.started":"2022-07-30T16:48:34.695181Z","shell.execute_reply":"2022-07-30T16:48:34.712614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set some directories\ntrain_zip_dir = '/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip'\ntest_zip_dir = '/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip'\nextract_dir = '/kaggle/working/extracted_data'\ntrain_dir = '/kaggle/working/train'\ntest_dir = '/kaggle/working/test'\nos.makedirs(train_dir+'/dog', exist_ok=True)\nos.makedirs(train_dir+'/cat', exist_ok=True)\nos.makedirs(test_dir+'/test_data', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:48:39.249070Z","iopub.execute_input":"2022-07-30T16:48:39.249626Z","iopub.status.idle":"2022-07-30T16:48:39.257383Z","shell.execute_reply.started":"2022-07-30T16:48:39.249565Z","shell.execute_reply":"2022-07-30T16:48:39.256086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extract data files\nimport zipfile\nwith zipfile.ZipFile(train_zip_dir, 'r') as zip_ref:\n    zip_ref.extractall(extract_dir)\n\nwith zipfile.ZipFile(test_zip_dir, 'r') as zip_ref:\n    zip_ref.extractall(extract_dir)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:48:45.006789Z","iopub.execute_input":"2022-07-30T16:48:45.007338Z","iopub.status.idle":"2022-07-30T16:49:05.250296Z","shell.execute_reply.started":"2022-07-30T16:48:45.007226Z","shell.execute_reply":"2022-07-30T16:49:05.249387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(rows, columns, images):\n    '''\n    Plot first 100 images\n    INPUTS:\n        rows: number of rows we want to display images on it\n        columns: number of images we want to display in each row\n        images: consist of 100 images each image consist 224*224 pixels\n        labels: truth value for each image\n    '''\n    \n    fig, x= plt.subplots(rows, columns, constrained_layout=True,figsize=(15,8))\n    plt.setp(x, xticks=[], yticks=[])\n    for i in range (len(x)):\n        for j in range (len(x[0])):\n            index = i*columns+j\n            img = cv2.imread(extract_dir+'/train/' + images[index])\n            x[i,j].imshow(cv2.resize(img, (150,150)))\n            \nnum_columns =5\ntrain_data = os.listdir(extract_dir+'/train/')[:100]\nplot_images(num_columns, num_columns, train_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:49:17.895659Z","iopub.execute_input":"2022-07-30T16:49:17.896076Z","iopub.status.idle":"2022-07-30T16:49:21.768149Z","shell.execute_reply.started":"2022-07-30T16:49:17.896018Z","shell.execute_reply":"2022-07-30T16:49:21.766903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to move the images tp their corresponding folders:\ndef move_files(train_path,test_path):\n    print('Moving Training Files ..')\n    time.sleep(1)\n    for i in tqdm(os.listdir(train_path)):        \n        if 'dog' in i:\n            shutil.copyfile(train_path+i,train_dir+'/dog/'+i )\n        elif 'cat' in i:\n            shutil.copyfile(train_path+i,train_dir+'/cat/'+i )\n        else:\n            print('unkown File', i)\n            \n    print('Moving Testing Files ..')\n    time.sleep(1)\n    for i in tqdm(os.listdir(test_path)):                \n        shutil.copyfile(test_path+i, test_dir+'/test_data/'+i)\n    #Delete original data    \n    shutil.rmtree(extract_dir)\n        \nmove_files(extract_dir+'/train/', extract_dir+'/test/')","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:50:00.174764Z","iopub.execute_input":"2022-07-30T16:50:00.175173Z","iopub.status.idle":"2022-07-30T16:50:09.835783Z","shell.execute_reply.started":"2022-07-30T16:50:00.175097Z","shell.execute_reply":"2022-07-30T16:50:09.834446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting Image and model parameters\n#Image_width,Image_height = 299,299\nbatch_size=64\ntotal_samples = 25000\nval_split=0.2\nn_train=total_samples*(1-val_split)\nn_val=total_samples*val_split\nnum_classes = 2\nprint(n_train,n_val)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:52:05.451136Z","iopub.execute_input":"2022-07-30T16:52:05.451532Z","iopub.status.idle":"2022-07-30T16:52:05.461116Z","shell.execute_reply.started":"2022-07-30T16:52:05.451472Z","shell.execute_reply":"2022-07-30T16:52:05.459888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define data pre-processing \ntrain_image_gen = ImageDataGenerator(rescale=1/255,rotation_range=20,horizontal_flip=True,validation_split=val_split)\n#Data loader to load each batch on the RAM at each step.\ntrain_generator = train_image_gen.flow_from_directory(train_dir, batch_size=batch_size,seed=42,subset='training',shuffle = True)\n\nval_generator = train_image_gen.flow_from_directory(train_dir,\n                                                    batch_size=batch_size,seed=42,subset='validation',\n                                                      shuffle = True)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:53:48.682300Z","iopub.execute_input":"2022-07-30T16:53:48.682655Z","iopub.status.idle":"2022-07-30T16:53:50.079652Z","shell.execute_reply.started":"2022-07-30T16:53:48.682600Z","shell.execute_reply":"2022-07-30T16:53:50.078625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard\n#Prepare call backs\nsavemodel=keras.callbacks.ModelCheckpoint(extract_dir,monitor='val_loss', mode='min',save_best_only=True,verbose=1)\nLR_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=2, factor=.5, min_lr=.00001)\nEarlyStop_callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True)\nmy_callback=[savemodel,EarlyStop_callback, LR_callback]","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:54:02.707801Z","iopub.execute_input":"2022-07-30T16:54:02.708556Z","iopub.status.idle":"2022-07-30T16:54:02.723062Z","shell.execute_reply.started":"2022-07-30T16:54:02.708496Z","shell.execute_reply":"2022-07-30T16:54:02.722135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_base_model(MODEL, img_size, lambda_fun = None):\n    inp = Input(shape = (img_size[0], img_size[1], 3))\n    x = inp\n    if lambda_fun:\n        x = Lambda(lambda_fun)(x)\n    \n    base_model = MODEL(input_tensor = x, weights = 'imagenet', include_top = False, pooling = 'avg')\n        \n    model = Model(inp, base_model.output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:54:18.274473Z","iopub.execute_input":"2022-07-30T16:54:18.274827Z","iopub.status.idle":"2022-07-30T16:54:18.281956Z","shell.execute_reply.started":"2022-07-30T16:54:18.274771Z","shell.execute_reply":"2022-07-30T16:54:18.280911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = create_base_model(VGG16, (224, 224), preprocess_input)\nmodel2 = create_base_model(ResNet50, (224, 224), preprocess_input)\nmodel3 = create_base_model(InceptionV3, (299, 299), preprocess_input)\nmodel1.trainable = False\nmodel2.trainable = False\nmodel3.trainable = False\n\ninpA = Input(shape = (224, 224, 3))\ninpB = Input(shape = (299, 299, 3))\nout1 = model1(inpA)\nout2 = model2(inpA)\nout3 = model3(inpB)\n\nx = Concatenate()([out1, out2, out3])                \nx = Dropout(0.6)(x)\nx = Dense(1, activation='sigmoid')(x)\nmultiple_pretained_model = Model([inpA, inpB], x)\n\nmultiple_pretained_model.compile(loss = 'binary_crossentropy',\n                          optimizer = 'rmsprop',\n                          metrics = ['accuracy'])\n\nmultiple_pretained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:55:13.300408Z","iopub.execute_input":"2022-07-30T16:55:13.300957Z","iopub.status.idle":"2022-07-30T16:55:31.493150Z","shell.execute_reply.started":"2022-07-30T16:55:13.300854Z","shell.execute_reply":"2022-07-30T16:55:31.492284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ResNet50","metadata":{}},{"cell_type":"code","source":"model_1 = Sequential()\nmodel_1.add(ResNet50(include_top = False, pooling = 'max', weights = 'imagenet'))\nmodel_1.add(Dense(1, activation = 'sigmoid'))\n\nmodel_1.layers[0].trainable = False \nmodel_1.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'binary_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:55:02.075748Z","iopub.execute_input":"2022-07-30T16:55:02.076105Z","iopub.status.idle":"2022-07-30T16:55:08.801405Z","shell.execute_reply.started":"2022-07-30T16:55:02.076025Z","shell.execute_reply":"2022-07-30T16:55:08.800379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"VGG16","metadata":{}},{"cell_type":"code","source":"model_2 = Sequential()\nmodel_2.add(VGG16(include_top = False, pooling = 'max', weights = 'imagenet'))\nmodel_2.add(Dense(2, activation = 'softmax'))\n\nmodel_2.layers[0].trainable = False \nmodel_2.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'binary_crossentropy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"InceptionV3","metadata":{}},{"cell_type":"code","source":"#Prepare the model.\nInceptionV3_base_model = InceptionV3(weights='imagenet', include_top=False)\nx = InceptionV3_base_model.output\nx= GlobalAveragePooling2D()(x)\nx = Dropout(0.2)(x)\nfinal_pred = Dense(num_classes,activation='softmax')(x)\nmodel_3 = Model(inputs=InceptionV3_base_model.input,outputs=final_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Freeze frist 276 layer of the network which is 311 layer.\n#Freeze low and mid level feature extractors which represented in earlier layers.\nlayer_to_Freeze=276    \nfor layer in model_3.layers[:layer_to_Freeze]:\n    layer.trainable =False\nfor layer in model_3.layers[layer_to_Freeze:]:\n    layer.trainable=True\n\nsgd = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\nmodel_3.compile(optimizer=sgd,loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training ...\nhistory_transfer_learning = multiple_pretained_model.fit_generator(train_generator,epochs=5,\n                                                steps_per_epoch=n_train//batch_size,\n                                                validation_data=val_generator,\n                                                validation_steps=n_val//batch_size,callbacks=my_callback)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:57:17.324155Z","iopub.execute_input":"2022-07-30T16:57:17.324585Z","iopub.status.idle":"2022-07-30T16:57:26.079805Z","shell.execute_reply.started":"2022-07-30T16:57:17.324527Z","shell.execute_reply":"2022-07-30T16:57:26.076836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = pd.DataFrame(model_3.history.history)\nloss[['loss', 'val_loss']].plot()\nloss[['accuracy', 'val_accuracy']].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Use Evaluate() or evalute_generator() to check your model accuracy on validation set.\nscore = model_1.evaluate_generator(val_generator,verbose=1)\nprint('Test loss: ', score[0])\nprint('Test accuracy', score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define data pre-processing \ntest_image_gen = ImageDataGenerator(rescale=1/255)\ntest_generator = test_image_gen.flow_from_directory(test_dir,target_size=(Image_width,Image_height),batch_size=1,seed=42,class_mode=None,shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_generator.reset()\ny_pred = model_3.predict_generator(generator=test_generator,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id':pd.Series(test_generator.filenames),'label':pd.Series(y_pred.clip(min=0.02,max=0.98)[:,1])})\nsubmission['id'] = submission.id.str.extract('(\\d+)')\nsubmission['id']=pd.to_numeric(submission['id'])\nsubmission.to_csv(\"Submission_InceptionV3.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission.nunique(axis=0)\nsubmission.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}